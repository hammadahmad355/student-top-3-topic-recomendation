# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aivgG8sLyWIKFNwgvakYS0o7pdkfC9Dh
"""

import pandas as pd

preferences_df = pd.read_csv("preferences_named.csv")
preferences_df.head()

students_df = pd.read_csv("students_performance_named.csv")
students_df.head()

import nltk
import string
from sklearn.feature_extraction.text import TfidfVectorizer

# Download stopwords
nltk.download('stopwords')
from nltk.corpus import stopwords

# Text cleaning function
def clean_text(text):
    text = text.lower()
    text = ''.join([c for c in text if c not in string.punctuation])
    tokens = text.split()
    tokens = [word for word in tokens if word not in stopwords.words('english')]
    return ' '.join(tokens)

# Apply cleaning
preferences_df['Cleaned_Text'] = preferences_df['Preference_Text'].apply(clean_text)

# TF-IDF Vectorization
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(preferences_df['Cleaned_Text'])

# Show TF-IDF shape
print("TF-IDF matrix shape:", tfidf_matrix.shape)

from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Step 1: Define available topics
topics = {
    'Mathematics': "numbers equations algebra calculus problem solving",
    'Science': "biology chemistry physics experiments discoveries",
    'History': "civilizations events historical figures cultures timelines",
    'English': "grammar vocabulary reading writing literature",
    'Computer Science': "programming coding software development logic AI"
}

# Step 2: Vectorize topic descriptions
topic_names = list(topics.keys())
topic_texts = list(topics.values())
topic_vectors = vectorizer.transform(topic_texts)

# Step 3: Compute cosine similarity between student preferences and topics
similarity_matrix = cosine_similarity(tfidf_matrix, topic_vectors)

# Step 4: Recommend top 3 topics for each student
top_n = 3
top_topics = np.argsort(similarity_matrix, axis=1)[:, -top_n:][:, ::-1]  # reverse to get highest first

# Step 5: Map topic indices to names
recommendations = []
for i, indices in enumerate(top_topics):
    recommended = [topic_names[idx] for idx in indices]
    recommendations.append(recommended)

# Add recommendations to preferences_df
preferences_df['Top_3_Topics'] = recommendations

# Show sample results
preferences_df[['Student_Name', 'Preference_Text', 'Top_3_Topics']].head()

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity

# Step 1: Select subject scores only
score_columns = ['Math_Score', 'Science_Score', 'History_Score', 'English_Score', 'CS_Score']
student_scores = students_df[score_columns]

# Step 2: Normalize scores to 0â€“1
scaler = MinMaxScaler()
normalized_scores = scaler.fit_transform(student_scores)

# Step 3: Compute cosine similarity between students
student_similarity = cosine_similarity(normalized_scores)

# Step 4: For each student, find top 3 most similar students (excluding self)
top_similar_students = []
for i in range(len(student_similarity)):
    sim_scores = student_similarity[i]
    top_indices = sim_scores.argsort()[-4:-1][::-1]  # Top 3, excluding self
    top_similar_students.append(top_indices)

# Step 5: Recommend topics where similar students scored high
collab_recommendations = []
subject_map = {
    0: 'Mathematics',
    1: 'Science',
    2: 'History',
    3: 'English',
    4: 'Computer Science'
}

for i, sim_indices in enumerate(top_similar_students):
    # Get scores of similar students
    combined_scores = np.mean(normalized_scores[sim_indices], axis=0)
    top_subjects_idx = combined_scores.argsort()[-3:][::-1]
    top_subjects = [subject_map[idx] for idx in top_subjects_idx]
    collab_recommendations.append(top_subjects)

# Add to students_df
students_df['Top_3_Collab_Topics'] = collab_recommendations

# Preview sample
students_df[['Student_Name', 'Top_3_Collab_Topics']].head()

from collections import Counter

# Step 1: Merge both datasets on Student_ID
merged_df = pd.merge(preferences_df, students_df, on='Student_ID')

# Step 2: Combine both recommendation lists
final_recommendations = []

for i in range(len(merged_df)):
    content_topics = merged_df.loc[i, 'Top_3_Topics']
    collab_topics = merged_df.loc[i, 'Top_3_Collab_Topics']

    # Assign weighted score: content=3, collab=2
    all_recs = content_topics + collab_topics
    weights = [3]*3 + [2]*3  # 3 weight for content, 2 for collab

    scored = Counter()
    for topic, weight in zip(all_recs, weights):
        scored[topic] += weight

    # Get top 3 final topics
    final = [topic for topic, _ in scored.most_common(3)]
    final_recommendations.append(final)

# Step 3: Add to merged dataframe
merged_df['Final_Top_3_Topics'] = final_recommendations

# Step 4: View results
merged_df[['Student_Name_x', 'Preference_Text', 'Top_3_Topics']].head()

students_df = pd.read_csv("students_performance_named.csv")
students_df.head()

preferences_df = pd.read_csv("preferences_named.csv")
preferences_df.head()

import streamlit as st
import pandas as pd

# Load the final merged data
df = pd.read_csv("final_recommendations.csv")

st.title("ðŸ“š Personalized Learning Path Recommender")

# Sidebar to pick student
student = st.selectbox("Select a student", df['Student_Name_x'].unique())

# Get the row
row = df[df['Student_Name_x'] == student].iloc[0]

# Show preference
st.subheader("ðŸ§  Student Preference")
st.write(row['Preference_Text'])

# Show recommendation
st.subheader("âœ… Recommended Topics")
st.write(row['Final_Top_3_Topics'])

# Optional: show academic scores
st.subheader("ðŸ“Š Academic Scores")
scores = row[['Math_Score', 'Science_Score', 'History_Score', 'English_Score', 'CS_Score']]
st.bar_chart(scores)

merged_df.to_csv("final_recommendations.csv", index=False)

